{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/examples/nlp/text_classification_with_transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/lingfeng/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/lingfeng/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Training sequences\n",
      "25000 Validation sequences\n",
      "(25000, 200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   5,   25,  100, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [  42, 1134,    6, ...,   72,   33,   32],\n",
       "       [5533,   15,    4, ...,   28,  126,  110],\n",
       "       [   0,    0,    0, ...,    7,   43,   50]], dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output, weights = self.att(inputs, inputs, return_attention_scores=True)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output), weights\n",
    "    \n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "    \n",
    "vocab_size = 20000  # Only consider the top 20k words\n",
    "maxlen = 200  # Only consider the first 200 words of each movie review\n",
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print(len(x_train), \"Training sequences\")\n",
    "print(len(x_val), \"Validation sequences\")\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 75s 95ms/step - loss: 0.5151 - accuracy: 0.7212 - val_loss: 0.3542 - val_accuracy: 0.8394\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 73s 94ms/step - loss: 0.1967 - accuracy: 0.9251 - val_loss: 0.3129 - val_accuracy: 0.8730\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 32  # Embedding size for each token\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x, attention_scores = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 0\n",
      "prediction: [[0.9693406  0.03065939]]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "token_and_position_embedding (None, 200, 32)           646400    \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform ((None, 200, 32), (None,  10656     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                660       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 657,758\n",
      "Trainable params: 657,758\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "test_index = 0\n",
    "\n",
    "test_case = x_val[test_index]\n",
    "print(\"label:\", y_val[test_index])\n",
    "\n",
    "import numpy as np\n",
    "print(\"prediction:\", model.predict(np.expand_dims(test_case,axis=0)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_score_results.shape: (1, 2, 200, 200)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_get_attention = keras.Model(inputs=model.inputs, outputs=model.get_layer(\"transformer_block\").output[1])\n",
    "\n",
    "attention_score_results = model_get_attention.predict(np.expand_dims(test_case,axis=0))\n",
    "\n",
    "print(\"attention_score_results.shape:\", attention_score_results.shape)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "attention_score_results_combine = attention_score_results[0][0] + attention_score_results[0][1] # two attention heads\n",
    "\n",
    "attention_score_results_sum = np.sum(attention_score_results_combine,axis=0)\n",
    "\n",
    "ax = sns.heatmap(np.expand_dims(attention_score_results_sum,axis=0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                     please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\n"
     ]
    }
   ],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()                                    \n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])            \n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, \"\") for i in test_case])\n",
    "\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "def colorize(words, color_array):\n",
    "    cmap=matplotlib.cm.Blues\n",
    "    template = '<span class=\"barcode\"; style=\"color: black; background-color: {}\">{}</span>'\n",
    "    colored_string = ''\n",
    "    for word, color in zip(words, color_array):\n",
    "        color = matplotlib.colors.rgb2hex(cmap(color)[:3])\n",
    "#         print(color)\n",
    "        colored_string += template.format(color, '&nbsp' + word + '&nbsp')\n",
    "    return colored_string\n",
    "\n",
    "words = decoded_review.split()\n",
    "\n",
    "words_len = len(words)\n",
    "\n",
    "attention_score_results_sum_cut = attention_score_results_sum[-words_len:]\n",
    "\n",
    "attention_score_results_sum_cut = attention_score_results_sum_cut / np.amax(attention_score_results_sum_cut)\n",
    "\n",
    "s = colorize(words, attention_score_results_sum_cut)\n",
    "\n",
    "# or simply save in an html file and open in browser\n",
    "with open('colorize.html', 'w') as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
